sales_job:
  input:
    path: "s3a://staging/Finance/BHCF20240331/BHCF20240331.txt"
    format: "csv"
    options:
      header: "true"
      inferSchema: "true"
      sep: "^"
      lineSep: "\n"

  output:
    path: "s3a://bronze/Finance/BHCF20240331/"
    table_name: BHCF
    format: "iceberg"
    mode: "overwrite"
    catalog: demo
    database: rest
sparkConf:
  spark.eventLog.enabled: true
  spark.history.fs.logDirectory: /home/iceberg/spark-events
  spark.sql.catalog.demo.s3.endpoint: http://minio:9000
  spark.eventLog.dir: /home/iceberg/spark-events
  spark.submit.deployMode: client
  spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false
  spark.sql.catalogImplementation: in-memory
  spark.sql.catalog.demo.warehouse: s3://warehouse/wh/
  spark.sql.catalog.demo.io-impl: org.apache.iceberg.aws.s3.S3FileIO
  spark.app.submitTime: 1757512685861
  spark.sql.extensions: org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
  spark.sql.catalog.demo.uri: http://rest:8181
  spark.sql.catalog.demo.type: rest
  spark.rdd.compress: True
  spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false
  spark.sql.catalog.demo: org.apache.iceberg.spark.SparkCatalog
  spark.sql.defaultCatalog: demo
  spark.sql.warehouse.dir: file:/home/iceberg/notebooks/spark-warehouse
  spark.ui.showConsoleProgress: true
  spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem
  spark.hadoop.fs.s3a.aws.credentials.provider: org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider
  spark.hadoop.fs.s3a.access.key: admin
  spark.hadoop.fs.s3a.secret.key: password
  spark.hadoop.fs.s3a.endpoint.region: us-east-1
  spark.hadoop.fs.s3a.endpoint: http://minio:9000
  spark.hadoop.fs.s3a.path.style.access: true
